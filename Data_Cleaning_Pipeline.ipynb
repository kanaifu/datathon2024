{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Helper Methods\n",
        "\n",
        "First, a method to check for emptiness among dataframes.\n",
        "\n",
        "Then, feature engineering methods."
      ],
      "metadata": {
        "id": "OMHhHDDeuNMP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RfPuyj_PuC8V"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def analyze_dataframe(df):\n",
        "    null_entries = {}\n",
        "    inf_entries = {}\n",
        "\n",
        "    for col in df.columns:\n",
        "        null_count = df[col].isnull().sum()\n",
        "        if null_count > 0:\n",
        "            null_entries[col] = null_count\n",
        "\n",
        "        inf_count = ((df[col] == np.inf) | (df[col] == -np.inf)).sum()\n",
        "        if inf_count > 0:\n",
        "            inf_entries[col] = inf_count\n",
        "\n",
        "    # Find the most frequent columns for null and inf values\n",
        "    most_frequent_null_column = max(null_entries, key=null_entries.get) if null_entries else None\n",
        "    most_frequent_inf_column = max(inf_entries, key=inf_entries.get) if inf_entries else None\n",
        "\n",
        "    print(100*'-')\n",
        "    print(\"Shape:\", df.shape)\n",
        "    print(\"Null entries:\", null_entries)\n",
        "    print(\"Infinite entries:\", inf_entries)\n",
        "    print(\"Most frequent column with null entries:\", most_frequent_null_column)\n",
        "    print(\"Most frequent column with infinite entries:\", most_frequent_inf_column)\n",
        "    print(100*'-')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def add_neighboring_wells(df):\n",
        "  pad_child_count = dict()\n",
        "  pad_ids = df[\"pad_id\"].values\n",
        "  for id in pad_ids:\n",
        "      if id in pad_child_count:\n",
        "        pad_child_count[id] += 1\n",
        "      else:\n",
        "        pad_child_count[id] = 1\n",
        "\n",
        "  df[\"num_neighboring_wells\"] = df[\"pad_id\"].map(pad_child_count)\n",
        "  return df\n",
        "\n",
        "def euclid_surface_bh_dist(df):\n",
        "    df['surface_bottom_dist'] = ((df['surface_x'] - df['bh_x'])**2 + (df['surface_y'] - df['bh_y'])**2)**0.5\n",
        "    return df\n",
        "\n",
        "def euclid_toe_dist(df):\n",
        "    df['toe_dist'] = ((df['horizontal_midpoint_x'] - df['horizontal_toe_x'])**2 + (df['horizontal_midpoint_y'] - df['horizontal_toe_y'])**2)**0.5\n",
        "    return df\n",
        "\n",
        "def surface_bottom_angle(df):\n",
        "   df['surface_bottom_angle'] = np.arctan2(df['surface_y'] - df['bh_y'], df['surface_x'] - df['bh_x'])\n",
        "   return df\n",
        "\n",
        "def toe_angle(df):\n",
        "   df['toe_angle'] = np.arctan2(df['horizontal_midpoint_y'] - df['horizontal_toe_y'], df['horizontal_midpoint_x'] - df['horizontal_toe_x'])\n",
        "   return df"
      ],
      "metadata": {
        "id": "FhS8XdXVuYpE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Cleaning Pipeline:\n",
        "\n",
        "Drop the 4 columns that are very empty – the 4 ratios\n",
        "\n",
        "Deal with np.inf entries\n",
        "\n",
        "Populate null categorical thingies with ‘Unknown’\n",
        "\n",
        "Impute null continuous thingies with average\n",
        "\n",
        "Engineer new features based on developed pipeline\n",
        "\n",
        "Drop features that are not necessary: standardized_operator_name, pad_id\n",
        "\n",
        "Now, everything should be full except the ‘PeakOilRate’. Since there’s nothing to be concluded with a missing PeakOilRate, we remove those entries\n",
        "\n",
        "Finally, one hot encode\n",
        "\n",
        "Final number of entries should be about 19k"
      ],
      "metadata": {
        "id": "xADBQ6HLufAV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/training (1).csv\")\n",
        "\n",
        "analyze_dataframe(df)"
      ],
      "metadata": {
        "id": "OO1fyGMIuiT2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop the columns that are very empty\n",
        "\n",
        "columns_to_drop = ['Unnamed: 0', 'ffs_frac_type', 'average_stage_length',\n",
        "       'average_proppant_per_stage', 'average_frac_fluid_per_stage',\n",
        "       'frac_seasoning']\n",
        "\n",
        "df = df.drop(columns=columns_to_drop)\n",
        "\n",
        "analyze_dataframe(df)"
      ],
      "metadata": {
        "id": "wA6rvfguujMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Deal with np.inf entries\n",
        "\n",
        "max_finite_value = df[df['frac_fluid_to_proppant_ratio'] != np.inf]['frac_fluid_to_proppant_ratio'].max()\n",
        "df['frac_fluid_to_proppant_ratio'] = df['frac_fluid_to_proppant_ratio'].replace([np.inf], max_finite_value)\n",
        "\n",
        "analyze_dataframe(df)"
      ],
      "metadata": {
        "id": "iuXeeW1iumPA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Populate null categorical columns w/ unknown\n",
        "categorical_cols = ['standardized_operator_name', 'relative_well_position', 'number_of_stages',\n",
        "                    'batch_frac_classification', 'well_family_relationship', 'frac_type', 'pad_id']\n",
        "\n",
        "cols_to_fill_with_minus1 = ['standardized_operator_name', 'pad_id', 'number_of_stages']\n",
        "\n",
        "cols_to_fill_with_unknown = [col for col in categorical_cols if col not in cols_to_fill_with_minus1]\n",
        "\n",
        "df[cols_to_fill_with_minus1] = df[cols_to_fill_with_minus1].fillna(-1)\n",
        "\n",
        "df[cols_to_fill_with_unknown] = df[cols_to_fill_with_unknown].fillna('Unknown')\n",
        "\n",
        "analyze_dataframe(df)"
      ],
      "metadata": {
        "id": "Qoup6Ckvungp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Impute null continuous features with average.\n",
        "\n",
        "continuous_cols = [col for col in df.columns if col not in categorical_cols]\n",
        "\n",
        "continuous_cols.remove('OilPeakRate')\n",
        "\n",
        "print(continuous_cols)\n",
        "\n",
        "df[continuous_cols] = df[continuous_cols].fillna(df[continuous_cols].median())\n",
        "\n",
        "analyze_dataframe(df)"
      ],
      "metadata": {
        "id": "7541qMdYuo6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Engineer new features based on developed pipeline\n",
        "\n",
        "add_neighboring_wells(df)\n",
        "euclid_surface_bh_dist(df)\n",
        "euclid_toe_dist(df)\n",
        "surface_bottom_angle(df)\n",
        "toe_angle(df)\n",
        "\n",
        "analyze_dataframe(df)"
      ],
      "metadata": {
        "id": "Oc59Xl-uuriH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop features that are not necessary: standardized_operator_name, pad_id\n",
        "\n",
        "uninterpretable_cols = ['standardized_operator_name', 'pad_id']\n",
        "df = df.drop(columns=uninterpretable_cols)\n",
        "\n",
        "analyze_dataframe(df)"
      ],
      "metadata": {
        "id": "HHjT1OsCusCw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove entries with 0 OilPeakRate\n",
        "\n",
        "df = df.dropna()\n",
        "\n",
        "analyze_dataframe(df)"
      ],
      "metadata": {
        "id": "blIfRYVTuuo8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# One hot encode and save\n",
        "\n",
        "categorical_cols = ['relative_well_position', 'number_of_stages', 'batch_frac_classification',\n",
        "                    'well_family_relationship', 'frac_type']\n",
        "\n",
        "df = pd.get_dummies(df, columns = categorical_cols)\n",
        "\n",
        "analyze_dataframe(df)\n",
        "\n",
        "df.to_csv(\"/content/final_product.csv\", index=True)"
      ],
      "metadata": {
        "id": "YAxstZ20uv-N"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}